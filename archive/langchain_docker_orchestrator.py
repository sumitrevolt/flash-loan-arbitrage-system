#!/usr/bin/env python3
"""
Enhanced LangChain Docker Orchestrator for MCP Servers & AI Agents
================================================================

This orchestrator manages the complete Docker ecosystem for:
‚úÖ Organized MCP servers (duplicates removed)
‚úÖ Optimized AI agents 
‚úÖ Enhanced infrastructure services
‚úÖ LangChain coordination layer
‚úÖ Real-time monitoring and health checks

Features:
- Intelligent container management
- Health monitoring with auto-recovery
- Service scaling and load balancing  
- LangChain agent coordination
- Performance optimization
- Comprehensive logging and metrics

Author: GitHub Copilot Multi-Agent System
Date: June 16, 2025
"""

import asyncio
import logging
import docker
import yaml
import signal
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, field
import aiohttp
import redis

# Enhanced logging setup
class ColoredFormatter(logging.Formatter):
    COLORS = {
        'DEBUG': '\033[36m',
        'INFO': '\033[32m', 
        'WARNING': '\033[33m',
        'ERROR': '\033[31m',
        'CRITICAL': '\033[35m',
    }
    RESET = '\033[0m'
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.RESET)
        record.levelname = f"{log_color}{record.levelname}{self.RESET}"
        return super().format(record)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('langchain_docker_orchestrator.log', encoding='utf-8')
    ]
)

for handler in logging.getLogger().handlers:
    if isinstance(handler, logging.StreamHandler):
        handler.setFormatter(ColoredFormatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))

logger = logging.getLogger(__name__)

@dataclass
class ServiceInfo:
    """Service information tracking"""
    name: str
    container_id: Optional[str] = None
    status: str = "unknown"
    port: int = 8000
    health_checks: int = 0
    health_failures: int = 0
    last_health_check: Optional[datetime] = None
    restart_count: int = 0
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    network_rx: int = 0
    network_tx: int = 0

@dataclass
class SystemMetrics:
    """System-wide metrics"""
    total_services: int = 0
    running_services: int = 0
    failed_services: int = 0
    total_restarts: int = 0
    average_cpu_usage: float = 0.0
    average_memory_usage: float = 0.0
    total_network_traffic: int = 0
    uptime: timedelta = field(default_factory=lambda: timedelta())

class LangChainDockerOrchestrator:
    """Enhanced Docker Orchestrator with LangChain Integration"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.absolute()
        self.docker_client = None
        self.redis_client = None
        
        # Service tracking
        self.services: Dict[str, ServiceInfo] = {}
        self.compose_files = []
        self.system_metrics = SystemMetrics()
        
        # Configuration
        self.config = {
            "health_check_interval": 30,  # seconds
            "max_restart_attempts": 3,
            "scaling_enabled": True,
            "auto_recovery": True,
            "performance_monitoring": True
        }
        
        # State management
        self.running = False
        self.start_time = datetime.now()
        
        logger.info("üöÄ LangChain Docker Orchestrator initialized")
    
    async def initialize(self):
        """Initialize the orchestrator"""
        logger.info("üèóÔ∏è Initializing LangChain Docker Orchestrator...")
        
        try:
            # Initialize Docker client
            self.docker_client = docker.from_env()
            logger.info("‚úÖ Docker client initialized")
            
            # Test Docker connectivity
            docker_info = self.docker_client.info()
            logger.info(f"‚úÖ Docker Engine: {docker_info.get('ServerVersion', 'Unknown')}")
            
            # Initialize Redis connection (optional)
            try:  
                self.redis_client = redis.Redis(host='localhost', port=6379, decode_responses=True)
                self.redis_client.ping()
                logger.info("‚úÖ Redis connection established")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Redis not available: {e}")
            
            # Discover compose files
            await self._discover_compose_files()
            
            # Load service configurations
            await self._load_service_configurations()
            
            logger.info("‚úÖ Orchestrator initialization complete")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Orchestrator initialization failed: {e}")
            return False
    
    async def _discover_compose_files(self):
        """Discover available Docker Compose files"""
        logger.info("üîç Discovering Docker Compose files...")
        
        compose_patterns = [
            "docker-compose.yml",
            "docker-compose.optimized.yml", 
            "docker/docker-compose.yml",
            "docker/docker-compose.optimized.yml",
            "docker/docker-compose.complete.yml"
        ]
        
        for pattern in compose_patterns:
            compose_path = self.project_root / pattern
            if compose_path.exists():
                self.compose_files.append(compose_path)
                logger.info(f"üìÑ Found compose file: {pattern}")
        
        if not self.compose_files:
            logger.warning("‚ö†Ô∏è No Docker Compose files found")
        else:
            logger.info(f"‚úÖ Discovered {len(self.compose_files)} compose files")
    
    async def _load_service_configurations(self):
        """Load service configurations from compose files"""
        logger.info("üìã Loading service configurations...")
        
        for compose_file in self.compose_files:
            try:
                with open(compose_file, 'r') as f:
                    compose_config = yaml.safe_load(f)
                
                services = compose_config.get('services', {})
                
                for service_name, service_config in services.items():
                    if service_name not in self.services:
                        # Extract port information
                        port = 8000
                        ports = service_config.get('ports', [])
                        if ports:
                            port_mapping = ports[0]
                            if ':' in str(port_mapping):
                                port = int(str(port_mapping).split(':')[0])
                        
                        self.services[service_name] = ServiceInfo(
                            name=service_name,
                            port=port
                        )
                
                logger.info(f"üìã Loaded {len(services)} services from {compose_file.name}")
                
            except Exception as e:
                logger.warning(f"Could not load {compose_file}: {e}")
        
        self.system_metrics.total_services = len(self.services)
        logger.info(f"‚úÖ Total services configured: {len(self.services)}")
    
    async def deploy_system(self, compose_file: Optional[str] = None):
        """Deploy the entire system"""
        logger.info("üöÄ Deploying LangChain MCP system...")
        
        try:
            # Determine which compose file to use
            if compose_file:
                target_compose = Path(compose_file)
            elif self.compose_files:
                # Prefer optimized version if available
                target_compose = None
                for compose_path in self.compose_files:
                    if 'optimized' in compose_path.name:
                        target_compose = compose_path
                        break
                if not target_compose:
                    target_compose = self.compose_files[0]
            else:
                logger.error("‚ùå No Docker Compose file available")
                return False
            
            logger.info(f"üìÑ Using compose file: {target_compose}")
            
            # Build images first
            await self._build_images(target_compose)
            
            # Start infrastructure services first
            await self._start_infrastructure_services(target_compose)
            
            # Wait for infrastructure to be ready
            await self._wait_for_infrastructure()
            
            # Start MCP servers
            await self._start_mcp_servers(target_compose)
            
            # Start AI agents
            await self._start_ai_agents(target_compose)
            
            # Start monitoring
            if self.config["performance_monitoring"]:
                asyncio.create_task(self._monitoring_loop())
            
            # Start health checking
            if self.config["auto_recovery"]:
                asyncio.create_task(self._health_check_loop())
            
            self.running = True
            logger.info("‚úÖ System deployment complete!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå System deployment failed: {e}")
            return False
    
    async def _build_images(self, compose_file: Path):
        """Build Docker images"""
        logger.info("üèóÔ∏è Building Docker images...")
        
        try:
            cmd = [
                "docker-compose",
                "-f", str(compose_file),
                "build",
                "--parallel"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=self.project_root
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info("‚úÖ Docker images built successfully")
            else:
                logger.error(f"‚ùå Docker build failed: {stderr.decode()}")
                raise Exception("Docker build failed")
                
        except Exception as e:
            logger.error(f"‚ùå Image building failed: {e}")
            raise
    
    async def _start_infrastructure_services(self, compose_file: Path):
        """Start infrastructure services (Redis, PostgreSQL, etc.)"""
        logger.info("üèóÔ∏è Starting infrastructure services...")
        
        infrastructure_services = [
            "redis", "postgres", "rabbitmq", "etcd"
        ]
        
        for service in infrastructure_services:
            if service in [s.name for s in self.services.values()]:
                await self._start_service(compose_file, service)
    
    async def _start_mcp_servers(self, compose_file: Path):
        """Start MCP server services"""
        logger.info("üì° Starting MCP servers...")
        
        mcp_services = [name for name in self.services.keys() if name.startswith('mcp-')]
        
        for service in mcp_services:
            await self._start_service(compose_file, service)
            # Small delay between starts to avoid overwhelming the system
            await asyncio.sleep(2)
    
    async def _start_ai_agents(self, compose_file: Path):
        """Start AI agent services"""
        logger.info("ü§ñ Starting AI agents...")
        
        agent_services = [name for name in self.services.keys() if name.startswith('ai-') or 'agent' in name]
        
        for service in agent_services:
            await self._start_service(compose_file, service)
            await asyncio.sleep(1)
    
    async def _start_service(self, compose_file: Path, service_name: str):
        """Start a specific service"""
        logger.info(f"üöÄ Starting service: {service_name}")
        
        try:
            cmd = [
                "docker-compose",
                "-f", str(compose_file),
                "up", "-d", service_name
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=self.project_root
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info(f"‚úÖ Service {service_name} started")
                if service_name in self.services:
                    self.services[service_name].status = "starting"
            else:
                logger.error(f"‚ùå Failed to start {service_name}: {stderr.decode()}")
                if service_name in self.services:
                    self.services[service_name].status = "failed"
                    
        except Exception as e:
            logger.error(f"‚ùå Error starting {service_name}: {e}")
            if service_name in self.services:
                self.services[service_name].status = "error"
    
    async def _wait_for_infrastructure(self):
        """Wait for infrastructure services to be ready"""
        logger.info("‚è≥ Waiting for infrastructure services...")
        
        max_wait = 120  # 2 minutes
        wait_time = 0
        
        while wait_time < max_wait:
            ready = True
            
            # Check Redis
            try:
                if self.redis_client:
                    self.redis_client.ping()
                    logger.debug("‚úÖ Redis is ready")
            except Exception:
                ready = False
                logger.debug("‚è≥ Waiting for Redis...")
            
            # Check PostgreSQL
            try:
                # Simple check - could be enhanced with actual DB connection
                containers = self.docker_client.containers.list(filters={"name": "postgres"})
                if containers and containers[0].status == "running":
                    logger.debug("‚úÖ PostgreSQL is ready")
                else:
                    ready = False
                    logger.debug("‚è≥ Waiting for PostgreSQL...")
            except Exception:
                ready = False
                logger.debug("‚è≥ Waiting for PostgreSQL...")
            
            if ready:
                logger.info("‚úÖ Infrastructure services are ready")
                break
            
            await asyncio.sleep(5)
            wait_time += 5
        
        if wait_time >= max_wait:
            logger.warning("‚ö†Ô∏è Infrastructure services may not be fully ready")
    
    async def _monitoring_loop(self):
        """Continuous monitoring loop"""
        logger.info("üìä Starting monitoring loop...")
        
        while self.running:
            try:
                await self._collect_metrics()
                await self._update_system_metrics()
                
                # Log metrics periodically
                if datetime.now().second % 30 == 0:  # Every 30 seconds
                    await self._log_system_status()
                
                await asyncio.sleep(10)  # Monitor every 10 seconds
                
            except Exception as e:
                logger.error(f"‚ùå Monitoring error: {e}")
                await asyncio.sleep(30)  # Wait longer on error
    
    async def _health_check_loop(self):
        """Continuous health check loop"""
        logger.info("üîç Starting health check loop...")
        
        while self.running:
            try:
                await self._perform_health_checks()
                await asyncio.sleep(self.config["health_check_interval"])
                
            except Exception as e:
                logger.error(f"‚ùå Health check error: {e}")
                await asyncio.sleep(60)  # Wait longer on error
    
    async def _collect_metrics(self):
        """Collect metrics from all services"""
        try:
            containers = self.docker_client.containers.list()
            
            for container in containers:
                service_name = container.name
                
                if service_name in self.services:
                    service_info = self.services[service_name]
                    
                    # Update container ID and status
                    service_info.container_id = container.id
                    service_info.status = container.status
                    
                    # Get container stats
                    try:
                        stats = container.stats(stream=False)
                        
                        # CPU usage
                        cpu_stats = stats.get('cpu_stats', {})
                        precpu_stats = stats.get('precpu_stats', {})
                        
                        if cpu_stats and precpu_stats:
                            cpu_usage = self._calculate_cpu_usage(cpu_stats, precpu_stats)
                            service_info.cpu_usage = cpu_usage
                        
                        # Memory usage
                        memory_stats = stats.get('memory_stats', {})
                        if memory_stats:
                            memory_usage = memory_stats.get('usage', 0)
                            memory_limit = memory_stats.get('limit', 1)
                            service_info.memory_usage = (memory_usage / memory_limit) * 100
                        
                        # Network stats
                        network_stats = stats.get('networks', {})
                        if network_stats:
                            for interface, net_data in network_stats.items():
                                service_info.network_rx += net_data.get('rx_bytes', 0)
                                service_info.network_tx += net_data.get('tx_bytes', 0)
                        
                    except Exception as e:
                        logger.debug(f"Could not get stats for {service_name}: {e}")
        
        except Exception as e:
            logger.error(f"‚ùå Metric collection failed: {e}")
    
    def _calculate_cpu_usage(self, cpu_stats: dict, precpu_stats: dict) -> float:
        """Calculate CPU usage percentage"""
        try:
            cpu_total = cpu_stats.get('cpu_usage', {}).get('total_usage', 0)
            precpu_total = precpu_stats.get('cpu_usage', {}).get('total_usage', 0)
            
            system_cpu = cpu_stats.get('system_cpu_usage', 0)
            presystem_cpu = precpu_stats.get('system_cpu_usage', 0)
            
            cpu_num = len(cpu_stats.get('cpu_usage', {}).get('percpu_usage', [1]))
            
            cpu_delta = cpu_total - precpu_total
            system_delta = system_cpu - presystem_cpu
            
            if system_delta > 0 and cpu_delta > 0:
                return (cpu_delta / system_delta) * cpu_num * 100.0
            
            return 0.0
            
        except Exception:
            return 0.0
    
    async def _update_system_metrics(self):
        """Update system-wide metrics"""
        running_count = sum(1 for s in self.services.values() if s.status == "running")
        failed_count = sum(1 for s in self.services.values() if s.status in ["failed", "error", "exited"])
        
        self.system_metrics.running_services = running_count
        self.system_metrics.failed_services = failed_count
        self.system_metrics.total_restarts = sum(s.restart_count for s in self.services.values())
        
        # Calculate averages
        if self.services:
            self.system_metrics.average_cpu_usage = sum(s.cpu_usage for s in self.services.values()) / len(self.services)
            self.system_metrics.average_memory_usage = sum(s.memory_usage for s in self.services.values()) / len(self.services)
            self.system_metrics.total_network_traffic = sum(s.network_rx + s.network_tx for s in self.services.values())
        
        self.system_metrics.uptime = datetime.now() - self.start_time
    
    async def _perform_health_checks(self):
        """Perform health checks on all services"""
        logger.debug("üîç Performing health checks...")
        
        for service_name, service_info in self.services.items():
            try:
                is_healthy = await self._check_service_health(service_info)
                
                service_info.health_checks += 1
                service_info.last_health_check = datetime.now()
                
                if not is_healthy:
                    service_info.health_failures += 1
                    logger.warning(f"‚ö†Ô∏è Health check failed for {service_name}")
                    
                    # Auto-recovery if enabled
                    if (self.config["auto_recovery"] and 
                        service_info.health_failures >= 3 and
                        service_info.restart_count < self.config["max_restart_attempts"]):
                        
                        await self._restart_service(service_name)
                
            except Exception as e:
                logger.error(f"‚ùå Health check error for {service_name}: {e}")
    
    async def _check_service_health(self, service_info: ServiceInfo) -> bool:
        """Check health of a specific service"""
        try:
            # HTTP health check
            timeout = aiohttp.ClientTimeout(total=10)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                health_url = f"http://localhost:{service_info.port}/health"
                
                async with session.get(health_url) as response:
                    return response.status == 200
        
        except Exception:
            # Fallback: check if container is running
            try:
                if service_info.container_id:
                    container = self.docker_client.containers.get(service_info.container_id)
                    return container.status == "running"
            except Exception:
                pass
            
            return False
    
    async def _restart_service(self, service_name: str):
        """Restart a specific service"""
        logger.info(f"üîÑ Restarting service: {service_name}")
        
        try:
            service_info = self.services[service_name]
            
            if service_info.container_id:
                container = self.docker_client.containers.get(service_info.container_id)
                container.restart()
                
                service_info.restart_count += 1
                service_info.health_failures = 0  # Reset failure count
                
                logger.info(f"‚úÖ Service {service_name} restarted successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to restart {service_name}: {e}")
    
    async def _log_system_status(self):
        """Log current system status"""
        uptime_str = str(self.system_metrics.uptime).split('.')[0]  # Remove microseconds
        
        logger.info(f"üìä System Status: {self.system_metrics.running_services}/{self.system_metrics.total_services} services running | "
                   f"CPU: {self.system_metrics.average_cpu_usage:.1f}% | "
                   f"Memory: {self.system_metrics.average_memory_usage:.1f}% | "
                   f"Uptime: {uptime_str}")
    
    async def stop_system(self, compose_file: Optional[str] = None):
        """Stop the entire system"""
        logger.info("‚èπÔ∏è Stopping LangChain MCP system...")
        
        self.running = False
        
        try:
            # Determine which compose file to use
            if compose_file:
                target_compose = Path(compose_file)
            elif self.compose_files:
                target_compose = self.compose_files[0]
            else:
                logger.error("‚ùå No Docker Compose file available")
                return False
            
            cmd = [
                "docker-compose",
                "-f", str(target_compose),
                "down"
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=self.project_root
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info("‚úÖ System stopped successfully")
                return True
            else:
                logger.error(f"‚ùå Failed to stop system: {stderr.decode()}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error stopping system: {e}")
            return False
    
    async def get_system_status(self) -> Dict[str, Any]:
        """Get comprehensive system status"""
        await self._collect_metrics()
        await self._update_system_metrics()
        
        return {
            "system_metrics": {
                "total_services": self.system_metrics.total_services,
                "running_services": self.system_metrics.running_services,
                "failed_services": self.system_metrics.failed_services,
                "total_restarts": self.system_metrics.total_restarts,
                "average_cpu_usage": round(self.system_metrics.average_cpu_usage, 2),
                "average_memory_usage": round(self.system_metrics.average_memory_usage, 2),
                "total_network_traffic": self.system_metrics.total_network_traffic,
                "uptime": str(self.system_metrics.uptime).split('.')[0]
            },
            "services": {
                name: {
                    "status": info.status,
                    "port": info.port,
                    "health_checks": info.health_checks,
                    "health_failures": info.health_failures,
                    "restart_count": info.restart_count,
                    "cpu_usage": round(info.cpu_usage, 2),
                    "memory_usage": round(info.memory_usage, 2),
                    "last_health_check": info.last_health_check.isoformat() if info.last_health_check else None
                }
                for name, info in self.services.items()
            },
            "configuration": self.config,
            "compose_files": [str(f) for f in self.compose_files]
        }
    
    def signal_handler(self, signum, frame):
        """Handle shutdown signals"""
        logger.info(f"üõë Received signal {signum}, shutting down...")
        self.running = False


async def main():
    """Main orchestrator function"""
    print("üöÄ LangChain Docker Orchestrator for MCP Servers & AI Agents")
    print("=" * 70)
    
    orchestrator = LangChainDockerOrchestrator()
    
    # Setup signal handlers
    for sig in [signal.SIGTERM, signal.SIGINT]:
        signal.signal(sig, orchestrator.signal_handler)
    
    try:
        # Initialize
        print("\nüèóÔ∏è Initializing orchestrator...")
        if not await orchestrator.initialize():
            print("‚ùå Initialization failed")
            return 1
        
        # Deploy system
        print("\nüöÄ Deploying system...")
        if not await orchestrator.deploy_system():
            print("‚ùå Deployment failed")
            return 1
        
        print("\n‚úÖ System deployed successfully!")
        print("\nüìä System Status:")
        status = await orchestrator.get_system_status()
        
        print(f"   Total Services: {status['system_metrics']['total_services']}")
        print(f"   Running Services: {status['system_metrics']['running_services']}")
        print(f"   Failed Services: {status['system_metrics']['failed_services']}")
        
        print("\nüéØ System is now running. Press Ctrl+C to stop.")
        
        # Keep running until interrupted
        while orchestrator.running:
            await asyncio.sleep(1)
    
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Shutdown requested by user")
    except Exception as e:
        logger.error(f"‚ùå Orchestrator error: {e}")
        return 1
    finally:
        print("\nüõë Stopping system...")
        await orchestrator.stop_system()
        print("‚úÖ System stopped")
    
    return 0


if __name__ == "__main__":
    exit(asyncio.run(main()))
